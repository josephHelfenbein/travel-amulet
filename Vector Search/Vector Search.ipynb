{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 43\u001b[0m\n\u001b[0;32m     11\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m getpass\u001b[38;5;241m.\u001b[39mgetpass(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI API Key:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Creates the vectors stored in TidB from the text file\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# docs = None\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#             else:\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#                 docs[docsIndex].metadata[key] = value\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Creates the Vector Store and saves it to TiDB\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# vector_store = TiDBVectorStore.from_documents(\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#     documents=docs,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m \n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Query the Vector Store\u001b[39;00m\n\u001b[0;32m     55\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m TiDBVectorStore\u001b[38;5;241m.\u001b[39mfrom_existing_vector_table(\n\u001b[0;32m     56\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m     57\u001b[0m     connection_string\u001b[38;5;241m=\u001b[39mtidb_connection_string,\n\u001b[0;32m     58\u001b[0m     table_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectors\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     59\u001b[0m     distance_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     60\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yashj\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import TiDBVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "tidb_connection_string = getpass.getpass(\"TiDB Connection String:\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "\n",
    "# Creates the vectors stored in TidB from the text file\n",
    "# docs = None\n",
    "\n",
    "# with open (\"country_data_markdown.txt\", \"r\", encoding=\"UTF-8\") as file:\n",
    "#     document = file.read()\n",
    "\n",
    "#     headers_to_split_on = [\n",
    "#         ('#', \"Country\"),\n",
    "#     ]\n",
    "\n",
    "#     markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "#     docs = markdown_splitter.split_text(document)\n",
    "\n",
    "# with open (\"country_metadata.txt\", 'r', encoding=\"UTF-8\") as file:\n",
    "#     docsIndex = 0\n",
    "#     for line in file:\n",
    "#         line = line.strip()\n",
    "#         if not line:\n",
    "#             docsIndex += 1\n",
    "#             continue\n",
    "#         if \":\" in line:\n",
    "#             key, value = line.split(\":\", 1)\n",
    "#             key = key.strip()\n",
    "#             value = value.strip()\n",
    "\n",
    "#             if key == \"Crime_Index\" or key == \"Download_Speed\" or key == \"Tap_Water_Index\":\n",
    "#                 docs[docsIndex].metadata[key] = float(value)\n",
    "#             else:\n",
    "#                 docs[docsIndex].metadata[key] = value\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Creates the Vector Store and saves it to TiDB\n",
    "# vector_store = TiDBVectorStore.from_documents(\n",
    "#     documents=docs,\n",
    "#     embedding=embeddings,\n",
    "#     table_name=\"vectors\",\n",
    "#     connection_string=tidb_connection_string,\n",
    "#     distance_strategy=\"cosine\", \n",
    "# )\n",
    "\n",
    "# Query the Vector Store\n",
    "vector_store = TiDBVectorStore.from_existing_vector_table(\n",
    "    embedding=embeddings,\n",
    "    connection_string=tidb_connection_string,\n",
    "    table_name=\"vectors\",\n",
    "    distance_strategy=\"cosine\",\n",
    ")\n",
    "\n",
    "# # Finds the most similar document to the query\n",
    "query = \"Find a country with people that speak English and Spanish, with warm weather, with extra hot spicy food, with people that follow Christianity, with a crime index of under 6, with landmarks, with many places for hiking, with broadband download speed of over 50 Mbps, with a tap water index of over 60, with no ongoing conflicts or regional tensions, with political stability and no political tensions, with a government that has a voting system, not in the continents of North America, and specifically not Bangladesh, Libya, Lebanon, Afghanistan, Somalia, Iran, Yemen, Syria, Russia, Myanmar, Venezuela, Iraq, South Sudan, Mali, Central African Republic, Burkina Faso, Haiti, Belarus, North Korea, Ukraine, Sudan, Mexico, Israel, or Palestine State.\"\n",
    "filters = {\n",
    "    \"Crime_Index\":{\"$lt\": 4.5},\n",
    "    \"Download_Speed\":{\"$gt\": 100},\n",
    "    \"Tap_Water_Index\":{\"$gt\": 80},\n",
    "}\n",
    "\n",
    "docs_with_score = vector_store.similarity_search_with_relevance_scores(query, filter=filters, k=20)\n",
    "# docs_with_score = vector_store.similarity_search_with_relevance_scores(query, k=20)\n",
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    # print(doc.metadata)\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
